{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the below code has been run and tested on Kaggle GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "from numpy import genfromtxt\n",
    "# import torchvision.transforms\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect if we have a GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = './self_driving_car.pth'\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 5\n",
    "batch_size = 256\n",
    "num_workers=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and preprocessing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize Dataset class. \"\"\"\n",
    "        \n",
    "        ### default directory where data is loaded ###\n",
    "        self.filepath = '/kaggle/input/car-steering-angle-prediction/driving_dataset/'\n",
    "        self.xs = []\n",
    "        self.ys = []\n",
    "\n",
    "        ### read data.txt ###\n",
    "        with open(\"/kaggle/input/car-steering-angle-prediction/driving_dataset/angles.txt\") as f:\n",
    "            for line in f:\n",
    "                self.xs.append(line.split()[0])\n",
    "                \n",
    "                 ### The paper by Nvidia uses the inverse of the turning radius, but steering wheel angle is proportional to the inverse of turning radius. #\n",
    "                   # So the steering wheel angle in radians is used as the output. ###\n",
    "        \n",
    "                self.ys.append(float(line.split()[1]) * 3.14159265 / 180)\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"we can call len(dataset) to return the size\"\"\"\n",
    "        return len(self.xs)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"support indexing such that dataset[i] can be used to get i-th sample\"\"\"\n",
    "        filename = self.xs[index]\n",
    "        \n",
    "        full_path_img = self.filepath + filename\n",
    "        img = cv2.imread(full_path_img)\n",
    "        \n",
    "        ### Resizing and normalizing images ###\n",
    "#         img_resize = cv2.resize(img, (200,66), interpolation = cv2.INTER_AREA)/ 255.0\n",
    "        img_resize = cv2.resize(img, (200,66), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        ### Returned the image converted to a numpy array with its corresponding steering angle ###\n",
    "        X_img = torch.from_numpy(img_resize).float()\n",
    "        Y_label = torch.tensor(self.ys[index])\n",
    "        return X_img,Y_label\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class that implements NVIDIA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The model includes ELU layers after each convolutional or fully connected layer to introduce non-linearity. \n",
    "### Standard RELU's as activation function can turn \"dead\", which means that they are never activated if the pre-activation value is always negative.\n",
    "### So ELU is used after each convolutional layer\n",
    "\n",
    "class ConvNet(nn.Module): \n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize ConvNet class to implement NVIDIA model. \"\"\"\n",
    "        \n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 24, kernel_size=5, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(24, 36, kernel_size=5, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(36, 48, kernel_size=5, stride=2),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(48, 64, kernel_size=3, stride=1),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "            \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=64*1*18, out_features=100),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=100, out_features=50),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(in_features=50, out_features=10),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(in_features=10, out_features=1)\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "\n",
    "        x = x.view(x.size(0), 3, 66, 200)\n",
    "        output = self.conv_layers(x)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.linear_layers(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplit:\n",
    "    \n",
    "    def __init__(self, dataset, test_train_split=0.8, val_train_split=0.2, shuffle=True):\n",
    "        \"\"\"Initialize dataSplit class\"\"\"\n",
    "\n",
    "        self.dataset = dataset\n",
    "        dataset_size = len(dataset)\n",
    "\n",
    "        self.indices = list(range(dataset_size))\n",
    "        test_split = int(np.floor(test_train_split * dataset_size))\n",
    "\n",
    "        if shuffle:\n",
    "            np.random.seed(3116)\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        train_indices, self.test_indices = self.indices[:test_split], self.indices[test_split:]\n",
    "        train_size = len(train_indices)\n",
    "        validation_split = int(np.floor((1 - val_train_split) * train_size))\n",
    "\n",
    "        self.train_indices = train_indices[ : validation_split]\n",
    "        self.val_indices = train_indices[validation_split:]\n",
    "        \n",
    "        self.train_sampler = SubsetRandomSampler(self.train_indices)\n",
    "        self.val_sampler = SubsetRandomSampler(self.val_indices)\n",
    "        self.test_sampler = SubsetRandomSampler(self.test_indices)\n",
    "\n",
    "    def get_split(self, batch_size=64, num_workers=8):\n",
    "        self.train_loader = torch.utils.data.DataLoader(self.dataset, batch_size=batch_size, sampler=self.train_sampler, shuffle=False, num_workers=num_workers)\n",
    "        self.val_loader = torch.utils.data.DataLoader(self.dataset, batch_size=batch_size, sampler=self.val_sampler, shuffle=False, num_workers=num_workers)\n",
    "        self.test_loader = torch.utils.data.DataLoader(self.dataset, batch_size=batch_size, sampler=self.test_sampler, shuffle=False, num_workers=num_workers)\n",
    "        return self.train_loader, self.val_loader, self.test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to train model on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader , criterion, optimizer, num_epochs=25):\n",
    "    \n",
    "    \"\"\"Train model on train set and validate it on validation set\"\"\"\n",
    "    \n",
    "    train_losses, val_losses,  = [], []\n",
    "    best_loss = 999999.0\n",
    "    start = time.time()\n",
    "\n",
    "        \n",
    "    ### Each epoch has a training and validation phase ###\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 10)\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        \n",
    "        ### Training phase ###\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels.view(-1,1))\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "\n",
    "        ### Validation phase ###\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(val_loader):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.view(-1,1))\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Average validation loss\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print('Train Loss: {:.2f}'.format(train_loss))\n",
    "        print('Val Loss: {:.2f}'.format(val_loss))\n",
    "\n",
    "        ### If the validation loss is at a minimum ###\n",
    "        if val_loss < best_loss:\n",
    "            torch.save(model,MODEL_SAVE_PATH)\n",
    "            best_loss = val_loss\n",
    "\n",
    "    time_elapsed = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset and split it into train, validate and test splits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset ...\n",
      "... Preparation of dataset done <==\n"
     ]
    }
   ],
   "source": [
    "print(\"==> Preparing dataset ...\")\n",
    "\n",
    "# create dataset\n",
    "dataset = CarDataset()\n",
    "\n",
    "# Creating data indices for training, validation splits and testing splits:\n",
    "split = DataSplit(dataset, shuffle=True)\n",
    "\n",
    "train_loader, val_loader, test_loader = split.get_split(batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "print(\"... Preparation of dataset done <==\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initialize model and transfer it to GPU if available ...\n",
      "... Initialization of model done <==\n"
     ]
    }
   ],
   "source": [
    "print(\"==> Initialize model and transfer it to GPU if available ...\")\n",
    "model = ConvNet().to(device)\n",
    "print(\"... Initialization of model done <==\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer and criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate model on validate set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 1/5\n",
      "Train Loss: 0.27\n",
      "Val Loss: 0.25\n",
      "----------\n",
      "Epoch 2/5\n",
      "Train Loss: 0.23\n",
      "Val Loss: 0.20\n",
      "----------\n",
      "Epoch 3/5\n",
      "Train Loss: 0.19\n",
      "Val Loss: 0.17\n",
      "----------\n",
      "Epoch 4/5\n",
      "Train Loss: 0.14\n",
      "Val Loss: 0.12\n",
      "----------\n",
      "Epoch 5/5\n",
      "Train Loss: 0.11\n",
      "Val Loss: 0.10\n",
      "Training complete in 9m 29s\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model, train_loader, val_loader,  criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer the model to GPU to evaluate it on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the saved model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_rmse = RMSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test images: 0.31\n"
     ]
    }
   ],
   "source": [
    "Rmse_total=0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_load(images)\n",
    "        loss = criterion_rmse(outputs, labels.view(-1,1))\n",
    "                \n",
    "        Rmse_total += loss.item()\n",
    "\n",
    "# print('RMSE on test images: {:.0f}'.format(Rmse_total))\n",
    "\n",
    "test_loss = Rmse_total / len(test_loader)\n",
    "print('RMSE on test images: {:.2f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)Cut_out for regularization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated helper classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutout:\n",
    "    \"\"\"\n",
    "    Randomly mask out one or more patches from an image.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        \"\"\"\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "        \"\"\"\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        h = img.size(1) #img.height \n",
    "        w = img.size(2) #img.width\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)        \n",
    "        img = img * mask                 \n",
    "\n",
    "        return img                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(image, steering_angle):\n",
    "    \"\"\"\n",
    "    Randomly flipt the image and adjust the steering angle.\n",
    "    \"\"\"\n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        steering_angle = -steering_angle\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarDatasetCutout(Dataset):\n",
    "\n",
    "    def __init__(self,transform = None):\n",
    "        \"\"\"Initialize Dataset class. \"\"\"\n",
    "        \n",
    "        ### default directory where data is loaded ###\n",
    "        self.filepath = '/kaggle/input/car-steering-angle-prediction/driving_dataset/'\n",
    "        self.xs = []\n",
    "        self.ys = []\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "        ### read data.txt ###\n",
    "        with open(\"/kaggle/input/car-steering-angle-prediction/driving_dataset/angles.txt\") as f:\n",
    "            for line in f:\n",
    "                self.xs.append(line.split()[0])\n",
    "                \n",
    "                 ### The paper by Nvidia uses the inverse of the turning radius, but steering wheel angle is proportional to the inverse of turning radius. #\n",
    "                   # So the steering wheel angle in radians is used as the output. ###\n",
    "        \n",
    "                self.ys.append(float(line.split()[1]) * 3.14159265 / 180)\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"we can call len(dataset) to return the size\"\"\"\n",
    "        return len(self.xs)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"support indexing such that dataset[i] can be used to get i-th sample\"\"\"\n",
    "        filename = self.xs[index]\n",
    "        \n",
    "        full_path_img = self.filepath + filename\n",
    "        img = cv2.imread(full_path_img)\n",
    "        \n",
    "        \n",
    "        # Randomly flip images\n",
    "        if np.random.rand() < 0.6:\n",
    "            X_img, Y_label = random_flip(img, self.ys[index])\n",
    "        else:\n",
    "            X_img = img\n",
    "            Y_label =  self.ys[index]\n",
    " \n",
    "        ### Resizing images ###\n",
    "        img_resize = cv2.resize(X_img, (200,66), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "\n",
    "        ### Returned the image tranformed to a numpy array with its corresponding steering angle ###        \n",
    "        X_img_transformed = self.transform(img_resize)\n",
    "        Y_label = Y_label\n",
    "        \n",
    "        \n",
    "        return X_img_transformed,Y_label      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_cutout(model, train_loader, val_loader , criterion, optimizer, num_epochs=25):\n",
    "    \n",
    "    \"\"\"Train model on train set and validate it on validation set\"\"\"\n",
    "    \n",
    "    train_losses, val_losses,  = [], []\n",
    "    best_loss = 10000.0\n",
    "    start = time.time()\n",
    "\n",
    "        \n",
    "    ### Each epoch has a training and validation phase ###\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 10)\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        \n",
    "        ### Training phase ###\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device,dtype=torch.float)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels.view(-1,1))\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "\n",
    "        ### Validation phase ###\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(val_loader):\n",
    "                images = images.to(device, dtype=torch.float)\n",
    "                labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.view(-1,1))\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Average validation loss\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print('Train Loss: {:.2f}'.format(train_loss))\n",
    "        print('Val Loss: {:.2f}'.format(val_loss))\n",
    "\n",
    "        ### If the validation loss is at a minimum ###\n",
    "        if val_loss < best_loss:\n",
    "            torch.save(model,MODEL_SAVE_PATH)\n",
    "            best_loss = val_loss\n",
    "\n",
    "    time_elapsed = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset after cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset ...\n",
      "... Preparation of dataset done <==\n"
     ]
    }
   ],
   "source": [
    "# Load Data with the transformations including cutout for regularization\n",
    "\n",
    "transformations = transforms.Compose([transforms.Lambda(lambda x: (x / 127.5) - 1.0), torchvision.transforms.ToTensor()])\n",
    "transformations.transforms.append(Cutout(n_holes=2, length=32)) # Apply cutout\n",
    "\n",
    "print(\"==> Preparing dataset ...\")\n",
    "\n",
    "# create dataset\n",
    "dataset = CarDatasetCutout(transformations)\n",
    "\n",
    "# Creating data indices for training, validation splits and testing splits:\n",
    "split = DataSplit(dataset, shuffle=True)\n",
    "\n",
    "train_loader_cutout, val_loader_cutout, test_loader_cutout = split.get_split(batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "print(\"... Preparation of dataset done <==\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initialize model and transfer it to GPU if available ...\n",
      "... Initialization of model done <==\n"
     ]
    }
   ],
   "source": [
    "print(\"==> Initialize model and transfer it to GPU if available ...\")\n",
    "model = ConvNet().to(device)\n",
    "print(\"... Initialization of model done <==\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate model on validate set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 1/5\n",
      "Train Loss: 0.33\n",
      "Val Loss: 0.34\n",
      "----------\n",
      "Epoch 2/5\n",
      "Train Loss: 0.33\n",
      "Val Loss: 0.33\n",
      "----------\n",
      "Epoch 3/5\n",
      "Train Loss: 0.33\n",
      "Val Loss: 0.33\n",
      "----------\n",
      "Epoch 4/5\n",
      "Train Loss: 0.33\n",
      "Val Loss: 0.33\n",
      "----------\n",
      "Epoch 5/5\n",
      "Train Loss: 0.33\n",
      "Val Loss: 0.34\n",
      "Training complete in 11m 17s\n"
     ]
    }
   ],
   "source": [
    "model_ft_cutout = train_model_cutout(model, train_loader_cutout, val_loader_cutout,  criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test images: 0.56\n"
     ]
    }
   ],
   "source": [
    "Rmse_total=0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(test_loader_cutout):\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_ft_cutout(images)\n",
    "        loss = criterion_rmse(outputs, labels.view(-1,1))\n",
    "                \n",
    "        Rmse_total += loss.item()\n",
    "\n",
    "# print('RMSE on test images: {:.0f}'.format(Rmse_total))\n",
    "\n",
    "test_loss = Rmse_total / len(test_loader)\n",
    "print('RMSE on test images: {:.2f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) MixUp for regularization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated HyperClasses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarDatasetMixup(Dataset):\n",
    "\n",
    "    def __init__(self,transform = None):\n",
    "        \"\"\"Initialize Dataset class. \"\"\"\n",
    "        \n",
    "        ### default directory where data is loaded ###\n",
    "        self.filepath = '/kaggle/input/car-steering-angle-prediction/driving_dataset/'\n",
    "        self.xs = []\n",
    "        self.ys = []\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "        ### read data.txt ###\n",
    "        with open(\"/kaggle/input/car-steering-angle-prediction/driving_dataset/angles.txt\") as f:\n",
    "            for line in f:\n",
    "                self.xs.append(line.split()[0])\n",
    "                \n",
    "                 ### The paper by Nvidia uses the inverse of the turning radius, but steering wheel angle is proportional to the inverse of turning radius. #\n",
    "                   # So the steering wheel angle in radians is used as the output. ###\n",
    "        \n",
    "                self.ys.append(float(line.split()[1]) * 3.14159265 / 180)\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"we can call len(dataset) to return the size\"\"\"\n",
    "        return len(self.xs)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"support indexing such that dataset[i] can be used to get i-th sample\"\"\"\n",
    "        filename = self.xs[index]\n",
    "        \n",
    "        full_path_img = self.filepath + filename\n",
    "        img = cv2.imread(full_path_img)\n",
    "        \n",
    "\n",
    "        X_img = img\n",
    "        Y_label =  self.ys[index]\n",
    " \n",
    "        ### Resizing images ###\n",
    "\n",
    "        img_resize = cv2.resize(X_img, (200,66), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "\n",
    "        ### Returned the image tranformed to a numpy array with its corresponding steering angle ###        \n",
    "        X_img_transformed = self.transform(img_resize)\n",
    "        Y_label = Y_label\n",
    "        \n",
    "        \n",
    "        return X_img_transformed,Y_label      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function implementing mixup regularization. It required one hot vector for labels. \n",
    "# But given dataset does not have continuos labels, so we cant convert labels to one hot vector. Due to this reason , I have used the actual labels of dataset as target.\n",
    "\n",
    "def mixup(data, targets, alpha):\n",
    "    indices = torch.randperm(data.size(0))\n",
    "    data2 = data[indices]\n",
    "    targets2 = targets[indices]\n",
    "\n",
    "\n",
    "    lam = torch.FloatTensor([np.random.beta(alpha, alpha)])\n",
    "    data = data * lam + data2 * (1 - lam)\n",
    "    targets = targets * lam + targets2 * (1 - lam)\n",
    "\n",
    "    return data, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_mixup(model, train_loader, val_loader , criterion, optimizer, num_epochs=25):\n",
    "    \n",
    "    \"\"\"Train model on train set and validate it on validation set\"\"\"\n",
    "    \n",
    "    train_losses, val_losses,  = [], []\n",
    "    best_loss = 99999.0\n",
    "    start = time.time()\n",
    "\n",
    "        \n",
    "    ### Each epoch has a training and validation phase ###\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 10)\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        \n",
    "        \n",
    "        ### Training phase ###\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            images,labels  = mixup(images, labels, 1)\n",
    "            \n",
    "            \n",
    "            images = images.to(device,dtype=torch.float)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels.view(-1,1))\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "\n",
    "        ### Validation phase ###\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(val_loader):\n",
    "                images = images.to(device, dtype=torch.float)\n",
    "                labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.view(-1,1))\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Average validation loss\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print('Train Loss: {:.2f}'.format(train_loss))\n",
    "        print('Val Loss: {:.2f}'.format(val_loss))\n",
    "\n",
    "        ### If the validation loss is at a minimum ###\n",
    "        if val_loss < best_loss:\n",
    "            torch.save(model,MODEL_SAVE_PATH)\n",
    "            best_loss = val_loss\n",
    "\n",
    "    time_elapsed = time.time() - start\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset ...\n",
      "... Preparation of dataset done <==\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "\n",
    "transformations = transforms.Compose([transforms.Lambda(lambda x: (x / 127.5) - 1.0), torchvision.transforms.ToTensor()])\n",
    "\n",
    "print(\"==> Preparing dataset ...\")\n",
    "\n",
    "# create dataset\n",
    "dataset = CarDatasetMixup(transformations)\n",
    "\n",
    "# Creating data indices for training, validation splits and testing splits:\n",
    "split = DataSplit(dataset, shuffle=True)\n",
    "\n",
    "train_loader_mixup, val_loader_mixup, test_loader_mixup = split.get_split(batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "print(\"... Preparation of dataset done <==\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate model on validate set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 1/5\n",
      "Train Loss: 0.25\n",
      "Val Loss: 0.34\n",
      "----------\n",
      "Epoch 2/5\n"
     ]
    }
   ],
   "source": [
    "model_mixup = train_model_mixup(model, train_loader_mixup, val_loader_mixup,  criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test images: 0.57\n"
     ]
    }
   ],
   "source": [
    "Rmse_total=0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(test_loader_mixup):\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_mixup(images)\n",
    "        loss = criterion_rmse(outputs, labels.view(-1,1))\n",
    "                \n",
    "        Rmse_total += loss.item()\n",
    "\n",
    "# print('RMSE on test images: {:.0f}'.format(Rmse_total))\n",
    "\n",
    "test_loss = Rmse_total / len(test_loader)\n",
    "print('RMSE on test images: {:.2f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) HyperBand Alogrithm for regularization:\n",
    "\n",
    "#### The Algorithm was taking alot of time to train. So I just used 2000 images from dataset and run the experiments on some hyper parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updated helper classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplitHyperBand:\n",
    "    \n",
    "    def __init__(self, dataset, test_train_split=0.8, val_train_split=0.2, shuffle=True):\n",
    "        \"\"\"Initialize dataSplit class\"\"\"\n",
    "\n",
    "        self.dataset = dataset        \n",
    "        dataset_size = 2000\n",
    "\n",
    "        self.indices = list(range(dataset_size))\n",
    "        test_split = int(np.floor(test_train_split * dataset_size))\n",
    "\n",
    "        if shuffle:\n",
    "            np.random.seed(3116)\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        train_indices, self.test_indices = self.indices[:test_split], self.indices[test_split:]\n",
    "        train_size = len(train_indices)\n",
    "        validation_split = int(np.floor((1 - val_train_split) * train_size))\n",
    "\n",
    "        self.train_indices = train_indices[ : validation_split]\n",
    "        self.val_indices = train_indices[validation_split:]\n",
    "        \n",
    "        self.train_sampler = SubsetRandomSampler(self.train_indices)\n",
    "        self.val_sampler = SubsetRandomSampler(self.val_indices)\n",
    "        self.test_sampler = SubsetRandomSampler(self.test_indices)\n",
    "\n",
    "    def get_split(self, batch_size=64, num_workers=8):\n",
    "        self.train_loader = torch.utils.data.DataLoader(self.dataset, batch_size=batch_size, sampler=self.train_sampler, shuffle=False, num_workers=num_workers)\n",
    "        self.val_loader = torch.utils.data.DataLoader(self.dataset, batch_size=batch_size, sampler=self.val_sampler, shuffle=False, num_workers=num_workers)\n",
    "        self.test_loader = torch.utils.data.DataLoader(self.dataset, batch_size=batch_size, sampler=self.test_sampler, shuffle=False, num_workers=num_workers)\n",
    "        return self.train_loader, self.val_loader, self.test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_hyperband(model, train_loader, val_loader , criterion, num_epochs, lr, wd ):\n",
    "    \n",
    "    \n",
    "    \"\"\"Train model on train set and validate it on validation set\"\"\"\n",
    "    \n",
    "    train_losses, val_losses,  = [], []\n",
    "    best_loss = 10000.0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        \n",
    "    ### Each epoch has a training and validation phase ###\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        ### Training phase ###\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            images,labels  = mixup(images, labels, 1)\n",
    "            \n",
    "            \n",
    "            images = images.to(device,dtype=torch.float)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels.view(-1,1))\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "\n",
    "        ### Validation phase ###\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(val_loader):\n",
    "                images = images.to(device, dtype=torch.float)\n",
    "                labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels.view(-1,1))\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Average validation loss\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        ### If the validation loss is at a minimum ###\n",
    "        if val_loss < best_loss:\n",
    "#             torch.save(model,MODEL_SAVE_PATH)\n",
    "            best_loss = val_loss\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hyperband:\n",
    "\n",
    "    def __init__(self,space):\n",
    "        self.search_space = space\n",
    "        self.myModel = ConvNet().to(device)   \n",
    "\n",
    "\n",
    "    def sample_space(self,n_samples):\n",
    "\n",
    "        config = np.array([np.random.choice(self.search_space[val],n_samples,replace=True) for val in self.search_space.keys()])\n",
    "        return np.transpose(config)\n",
    "    \n",
    "    def model_hyperband(self, epochs, params):       \n",
    "\n",
    "        print('\\n \\t Running the configurations ',params,' for - ',int(epochs),' epochs')\n",
    "        \n",
    "        matrix = train_model_hyperband(self.myModel, train_loader_hyperband, val_loader_hyperband, criterion, num_epochs=int(epochs), lr=float(params[0]),wd = float(params[1]))\n",
    "        return matrix\n",
    "        \n",
    "\n",
    "\n",
    "    def search(self,max_iter=5,eta=3,skip_last=1):\n",
    "\n",
    "        logeta = lambda x: math.log(x) / math.log(eta)\n",
    "        s_max = int(logeta(max_iter))\n",
    "        B = (s_max + 1) * max_iter\n",
    "\n",
    "        result = np.array([])\n",
    "        best_config = np.array([])\n",
    "\n",
    "        ## this loop denotes the no. of unique run of successive halving\n",
    "        for s in reversed(range(s_max + 1)):\n",
    "\n",
    "            print('\\n  Current bracket number - ', s)\n",
    "\n",
    "            if skip_last:\n",
    "                if s == 0: break\n",
    "\n",
    "            n = int(math.ceil(int(B / max_iter / (s + 1)) * eta ** s))  # number of configurations to sample for at starting of given bracket\n",
    "            r = max_iter * eta ** (-s)  # number of resources at starting for given bracket\n",
    "\n",
    "            T = self.sample_space(n)  # sampling from the search space\n",
    "            metric = np.array([])\n",
    "\n",
    "            ## this loop runs the successive halving for a given bracket\n",
    "            for i in range(s + 1):\n",
    "\n",
    "                n_i = n * eta ** (-i)  # no. of configs for given successive halving\n",
    "                r_i = r * eta ** (i)  # no. of resources for given successive halving\n",
    "                val_metric = np.array([self.model_hyperband(r_i,t) for t in T])  # getting the val_metric for each config\n",
    "                T = np.array([T[i] for i in reversed(np.argsort(val_metric)[int(n / eta):])])  # implementing the successive halving\n",
    "                metric = np.append(metric,np.max(val_metric))\n",
    "                \n",
    "                \n",
    "                print('\\n\\n \\t number of reduction/successive halving done - ', i)\n",
    "\n",
    "            best_config = np.append(best_config, T[:2])  # keeping track of the best config from each bracket\n",
    "            result = np.append(result,metric[-1])\n",
    "\n",
    "        best = best_config[np.argmax(result)]\n",
    "        print('\\n\\n the Best configuration - ', best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset ...\n",
      "... Preparation of dataset done <==\n"
     ]
    }
   ],
   "source": [
    "print(\"==> Preparing dataset ...\")\n",
    "\n",
    "# create dataset\n",
    "dataset = CarDataset()\n",
    "\n",
    "# Creating data indices for training, validation splits and testing splits:\n",
    "split = DataSplitHyperBand(dataset, shuffle=True)\n",
    "\n",
    "train_loader_hyperband, val_loader_hyperband, test_loader_hyperband = split.get_split(batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "print(\"... Preparation of dataset done <==\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run hyper band algorithm to best optimal paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Current bracket number -  1\n",
      "\n",
      " \t running the config  [0.01 0.1 ]  for -  1  epochs\n",
      "\n",
      " \t running the config  [0.001 0.   ]  for -  1  epochs\n",
      "\n",
      " \t running the config  [0.001 0.   ]  for -  1  epochs\n",
      "\n",
      "\n",
      " \t number of reduction/successive halving done -  0\n",
      "\n",
      " \t running the config  [0.01 0.1 ]  for -  5  epochs\n",
      "\n",
      " \t running the config  [0.001 0.   ]  for -  5  epochs\n",
      "\n",
      "\n",
      " \t number of reduction/successive halving done -  1\n",
      "\n",
      "  Current bracket number -  0\n",
      "\n",
      "\n",
      " the best configuration -  0.1\n"
     ]
    }
   ],
   "source": [
    "## defining the search space and run hyperband to get best paramaters on which model performed best!!\n",
    "\n",
    "space = {'lr': np.array([1e-4, 1e-3, 1e-2]), 'weight_decay': np.array([1e-2,1e-1,0])}\n",
    "\n",
    "hyper_band = hyperband(space)\n",
    "\n",
    "hyper_band.search()   ## calling the search function from hyperband"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
