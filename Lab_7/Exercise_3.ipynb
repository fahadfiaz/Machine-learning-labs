{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from operator import itemgetter\n",
    "import functools\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to split the dataset into train, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df,targetcol):\n",
    "    \n",
    "    X = df\n",
    "    Y = targetcol \n",
    "    X_copy = X.copy()\n",
    "    \n",
    "    Xtrain = X_copy.sample(frac=0.70, random_state=0)\n",
    "    Xtest = X_copy.drop(Xtrain.index)\n",
    "    Xtest_copy = Xtest.copy()\n",
    "    Xtest = Xtest_copy.sample(frac=0.50, random_state=1)\n",
    "    Xvalidate = Xtest_copy.drop(Xtest.index)\n",
    "    \n",
    "    # Normalizing features \n",
    "    norm_Xtrain = np.linalg.norm(Xtrain, axis = 1, keepdims = True)\n",
    "    Xtrain = Xtrain / norm_Xtrain\n",
    "    norm_Xtest = np.linalg.norm(Xtest, axis = 1, keepdims = True)\n",
    "    Xtest = Xtest / norm_Xtest\n",
    "    norm_Xval = np.linalg.norm(Xvalidate, axis = 1, keepdims = True)\n",
    "    Xval = Xvalidate / norm_Xval\n",
    "    \n",
    "    Y_copy = Y.copy()\n",
    "    Ytrain = Y_copy.sample(frac=0.70, random_state=0)\n",
    "    Ytest = Y_copy.drop(Ytrain.index)\n",
    "    Ytest_copy = Ytest.copy()\n",
    "    Ytest = Ytest_copy.sample(frac=0.50, random_state=1)\n",
    "    \n",
    "    Yvalidate = Ytest_copy.drop(Ytest.index)\n",
    "    \n",
    "    Ytrain = np.matrix(Ytrain)\n",
    "    Ytest = np.matrix(Ytest)\n",
    "    Yval = np.matrix(Yvalidate)\n",
    "    \n",
    "    return Xtrain, Ytrain, Xval, Yval, Xtest, Ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist(a , b):\n",
    "    distance = np.sum(np.square(a-b))\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist2(a , b):\n",
    "    distance = np.sum(np.square(a-b),axis=1)\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the distance measure point wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function take three paramters -> one row of training dataset, one row of validation dataset and maximum distance \n",
    "###                                    -> till that time.\n",
    "\n",
    "### First it calculate the the euclidean distance between respective columns of two rows. Then it check if this distance is \n",
    "### greater than maximum distance till that time, it will break loop and return the flag false along with maximum distance. This\n",
    "### is why this method runs faster than normal k-nearest neighbours method.\n",
    "\n",
    "### But, if that is not the case, then it will save the distance and do this procedure for all columns. If the loop does not\n",
    "### break, then it means the distance between the current two rows is minimum then this function return true flag along with \n",
    "### the minimum calculated distance\n",
    "\n",
    "def dist_measure(a , b, max_dist_till_now):\n",
    "    total_dist = 0\n",
    "    \n",
    "    for i,j in zip(a,b):\n",
    "        difference = np.sqrt(np.square(i-j))\n",
    "        total_dist += difference\n",
    "        if total_dist > max_dist_till_now:\n",
    "            break;\n",
    "    \n",
    "    if total_dist > max_dist_till_now:\n",
    "        return False, max_dist_till_now\n",
    "    else:\n",
    "        return True,total_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate the k- nearest distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This function calculate the k neareast distances. It first calculate the distance of query row with k- rows of train dataset and save it in distance array tp. Then for each other row of train dataset, it call dist_measure method.If dist_measure method returns true then it replace the maximum distance from k-nearest distances array with distance return by dist_measure method.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_nn(df , query , k):\n",
    "    tp = np.zeros(df.shape[0])\n",
    "\n",
    "    specific_rows = df.iloc[:k,:]\n",
    "    i=0\n",
    "    for index,row in specific_rows.iterrows():\n",
    "        tp[i] = eucl_dist(row, query)\n",
    "        i=i+1\n",
    "    \n",
    "    df_c = df.copy()\n",
    "    remaining_rows = df_c.drop(specific_rows.index)\n",
    "    \n",
    "    \n",
    "    for index,row in remaining_rows.iterrows():\n",
    "        \n",
    "        flag, dist =  dist_measure(row, query, max(tp))\n",
    "        if flag:\n",
    "            ind = np.argmax(tp)\n",
    "            tp[ind] = 0\n",
    "            tp[i] = dist\n",
    "            \n",
    "        i = i + 1\n",
    "    \n",
    "    agg =  np.nonzero(tp)[0]\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to  calculate k-neareast neighbours and do majority voting to get final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x , y , query, k):\n",
    "    predictions = []\n",
    "    \n",
    "    for index,row1 in query.iterrows():\n",
    "        k_min = best_nn(x , row1 , k)\n",
    "        m = y[k_min].tolist()\n",
    "        predictions.append(max(m , key=m.count))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get accuracy on specific dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(a , p):\n",
    "\n",
    "    count = 0\n",
    "    for i ,j in zip(a , p):\n",
    "        if (i == j):\n",
    "            count += 1\n",
    "    return (count/a.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Crop Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crop dataset was the largest dataset in the repository. We can confirm it in exercise 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset Shape  (24000, 47)\n",
      "Check if dataset has null values or missing values!!!  False\n"
     ]
    }
   ],
   "source": [
    "train_pt = \"./UCRArchive_2018\\\\\" + \"Crop\" + \"\\\\\"+ \"Crop\" + \"_TRAIN.tsv\"\n",
    "test_pt = \"./UCRArchive_2018\\\\\" + \"Crop\" + \"\\\\\"+ \"Crop\" + \"_TEST.tsv\"\n",
    "df_train = pd.read_csv(train_pt, sep='\\t', header=None)\n",
    "df_test = pd.read_csv(test_pt, sep='\\t', header=None)\n",
    "df_full = df_train.append(df_test)\n",
    "df_full.reset_index(drop=True, inplace=True)\n",
    "print(\"Full Dataset Shape \",df_full.shape )\n",
    "print( \"Check if dataset has null values or missing values!!! \",np.isnan(df_train.values).any()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Dataset was very large and took alot of time to perform experiments so I have downscaled the dataset by doing stratified sampling. I took 20 samples per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample belonging to class: 1 are  20\n",
      "Total sample belonging to class: 2 are  20\n",
      "Total sample belonging to class: 3 are  20\n",
      "Total sample belonging to class: 4 are  20\n",
      "Total sample belonging to class: 5 are  20\n",
      "Total sample belonging to class: 6 are  20\n",
      "Total sample belonging to class: 7 are  20\n",
      "Total sample belonging to class: 8 are  20\n",
      "Total sample belonging to class: 9 are  20\n",
      "Total sample belonging to class: 10 are  20\n",
      "Total sample belonging to class: 11 are  20\n",
      "Total sample belonging to class: 12 are  20\n",
      "Total sample belonging to class: 13 are  20\n",
      "Total sample belonging to class: 14 are  20\n",
      "Total sample belonging to class: 15 are  20\n",
      "Total sample belonging to class: 16 are  20\n",
      "Total sample belonging to class: 17 are  20\n",
      "Total sample belonging to class: 18 are  20\n",
      "Total sample belonging to class: 19 are  20\n",
      "Total sample belonging to class: 20 are  20\n",
      "Total sample belonging to class: 21 are  20\n",
      "Total sample belonging to class: 22 are  20\n",
      "Total sample belonging to class: 23 are  20\n",
      "Total sample belonging to class: 24 are  20\n"
     ]
    }
   ],
   "source": [
    "df2 = df_full.groupby(df_full.columns[0]).apply(lambda x: x.sample(20))\n",
    "for i in range (1,25):\n",
    "    print(\"Total sample belonging to class:\" , i , \"are \",df2[df2[0]==i].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset after sampling:  (480, 47)\n"
     ]
    }
   ],
   "source": [
    "print(\"Full dataset after sampling: \",df2.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate train and prediction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Training Dataset Shape  (480, 46)\n",
      "Full Testing Dataset Shape  (480,)\n",
      "Check if dataset has null values or missing values!!!  False\n"
     ]
    }
   ],
   "source": [
    "df_train = df2.iloc[:,1:]\n",
    "df_test = df2.iloc[:,0]\n",
    "print(\"Full Training Dataset Shape \",df_train.shape)\n",
    "print(\"Full Testing Dataset Shape \",df_test.shape)\n",
    "print( \"Check if dataset has null values or missing values!!! \",np.isnan(df_train.values).any()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Partial Distances/Lower Bounding K-nearest neighbour algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed for k  1\n",
      "processed for k  2\n",
      "processed for k  3\n",
      "processed for k  4\n",
      "processed for k  5\n",
      "processed for k  6\n",
      "processed for k  7\n",
      "processed for k  8\n",
      "processed for k  9\n",
      "processed for k  10\n",
      "--- 43.766204833984375 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "listAccr = np.zeros(11)\n",
    "\n",
    "for k1 in range(0,10):\n",
    "        \n",
    "        # Function to split the train, prediction sets to train,test,validation sets\n",
    "        Xtrain, Ytrain, Xval, Yval, Xtest, Ytest = split(df_train,df_test)\n",
    "        \n",
    "        pred = prediction(Xtrain, np.array(Ytrain)[0], Xval, k1+1)\n",
    "        \n",
    "        listAccr[k1+1] = accuracy(np.array(Yval)[0], pred)\n",
    "        \n",
    "        print(\"processed for k \", k1+1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set accuracies for each K values. Here list index represent K value!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , 22.22222222,  8.33333333,  9.72222222, 15.27777778,\n",
       "       19.44444444, 11.11111111, 18.05555556, 18.05555556, 16.66666667,\n",
       "       18.05555556])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listAccr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best K value with highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on validation set:  22.22222222222222  with k:  1\n"
     ]
    }
   ],
   "source": [
    "indx = np.unravel_index(np.nanargmax(listAccr), listAccr.shape)\n",
    "print(\"Best accuracy on validation set: \",listAccr[indx[0]], \" with k: \",  indx[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the best k value on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set 25.0\n"
     ]
    }
   ],
   "source": [
    "Xtrain0, Ytrain0, Xval0, Yval0, Xtest0, Ytest0 = split(df_train,df_test)    \n",
    "pred = prediction(Xtrain0, np.array(Ytrain0)[0], Xtest0, 1)\n",
    "\n",
    "print('Accuracy on test set', accuracy(np.array(Ytest0)[0], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will run the simple Knn algorithm without lower bounding on crop dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only these two functions needed to be changed for simple K nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now this function calculate all the distances of query row with traininig dataset and select the min k distances\n",
    "def best_nn_2(df , query , k):\n",
    "    distance =[]    \n",
    "\n",
    "    for j,row2 in df.iterrows():\n",
    "        distance.append(eucl_dist(row2, query))        \n",
    "    agg = np.argsort(distance)[:k]\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction2(x , y , query, k):\n",
    "    predictions = []\n",
    "    \n",
    "    for index,row1 in query.iterrows():        \n",
    "        k_min = best_nn_2(x , row1 , k)\n",
    "        m = y[k_min].tolist()\n",
    "        predictions.append(max(m , key=m.count))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the simple knn algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed for k  1\n",
      "processed for k  2\n",
      "processed for k  3\n",
      "processed for k  4\n",
      "processed for k  5\n",
      "processed for k  6\n",
      "processed for k  7\n",
      "processed for k  8\n",
      "processed for k  9\n",
      "processed for k  10\n",
      "--- 135.97897911071777 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "listAccr = np.zeros(11)\n",
    "for k1 in range(0,10):\n",
    "\n",
    "        Xtrain, Ytrain, Xval, Yval, Xtest, Ytest = split(df_train,df_test)\n",
    "        \n",
    "        pred = prediction2(Xtrain, np.array(Ytrain)[0], Xval, k1+1)\n",
    "        \n",
    "        listAccr[k1+1] = accuracy(np.array(Yval)[0], pred)\n",
    "        \n",
    "        print(\"processed for k \", k1+1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set accuracies for each K values. Here list index represent K value!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , 50.        , 50.        , 52.77777778, 54.16666667,\n",
       "       50.        , 50.        , 54.16666667, 51.38888889, 48.61111111,\n",
       "       50.        ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listAccr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best K value with highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on validation set:  54.166666666666664  with k:  4\n"
     ]
    }
   ],
   "source": [
    "indx = np.unravel_index(np.nanargmax(listAccr), listAccr.shape)\n",
    "print(\"Best accuracy on validation set: \",listAccr[indx[0]], \" with k: \",  indx[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the best k value on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy  51.388888888888886\n"
     ]
    }
   ],
   "source": [
    "Xtrain0, Ytrain0, Xval0, Yval0, Xtest0, Ytest0 = split(df_train,df_test)\n",
    "    \n",
    "pred = prediction2(Xtrain0, np.array(Ytrain0)[0], Xtest0, 4)\n",
    "print('Test Accuracy ', accuracy(np.array(Ytest0)[0], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When we use partial distances/lower bounding k nearest neighbour algorithm, we got total algorithm running time of 43.7 seconds which is less than simple k nearest neighbour algorithm which had 135.9 seconds total running time. These results showed that  partial distance/lower bounding knn is infact faster than simple knn. But it comes at the cost of accuracy as accuracy of simple knn was better than partial distance knn. \n",
    "#### But I have run the experiments on the downscale dataset so, its possible that when we run the experiments on full dataset, then running time difference may by significantly larger among two algorithms and accuracy difference may be smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
