{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this cell to install surprise library that we will use in exercise 3\n",
    "# ! pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "##### In this task, matrix factorization has been implemented using Stochastic Gradient Descent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    movieLdf = pd.read_csv(\"u.data\", delimiter=\"\\t\", header=None)\n",
    "    movieLdf = movieLdf.drop(movieLdf.columns[3], axis=1)\n",
    "    return movieLdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFn(data, p, q, lamda):\n",
    "    loss = 0\n",
    "    for x in data:\n",
    "        a = (x[2]-predict(p,q,x[0]-1,x[1]-1))*(x[2]-predict(p,q,x[0]-1,x[1]-1))\n",
    "        b = lamda * (np.dot(p[x[0]-1].T, p[x[0]-1]) + np.dot(q[x[1]-1].T, q[x[1]-1]))\n",
    "        loss = loss + ( a + b )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(p, q, user, item):\n",
    "    return np.dot(p[user].T, q[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Following function has been created for Stochastic gradient descent algorithm (Algorithm LearnLatentFactors) as described on slide 29:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainMF(data, valid, nUsers, nItems, learnR, lamda, factors, epochs, eps):\n",
    "    p = np.random.normal(size=((nUsers, factors)))\n",
    "    q = np.random.normal(size=((nItems, factors)))\n",
    "    \n",
    "    trainRMSE=[]\n",
    "    validRMSE=[]\n",
    "    for i in range(epochs):\n",
    "        np.random.shuffle(data)\n",
    "        prevFnV = lossFn(data, p, q, lamda)\n",
    "        for x in data:\n",
    "            l = x[2] - predict(p, q, x[0]-1, x[1]-1)\n",
    "\n",
    "            p[x[0]-1] = p[x[0]-1] + learnR * (l*q[x[1]-1] - lamda*p[x[0]-1])\n",
    "            q[x[1]-1] = q[x[0]-1] + learnR * (l*p[x[0]-1] - lamda*q[x[1]-1])\n",
    "            \n",
    "        trainRMSE.append(np.sqrt(np.mean(np.square(data[:,2] -\\\n",
    "                        [predict(p, q, x[0]-1, x[1]-1) for x in data]))))\n",
    "        \n",
    "        if valid is not None:\n",
    "            validRMSE.append(np.sqrt(np.mean(np.square(valid[:,2] -\\\n",
    "                            [predict(p, q, x[0]-1, x[1]-1) for x in valid]))))\n",
    "        \n",
    "        nextFnV = lossFn(data, p, q, lamda)\n",
    "        \n",
    "        if(np.abs(prevFnV-nextFnV) < eps):\n",
    "            break;\n",
    "            \n",
    "    return p, q, trainRMSE, validRMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following function is used for K-fold split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset, folds=3):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = np.copy(dataset)\n",
    "    fold_size = math.ceil(len(dataset) / folds)\n",
    "    for i in range(folds):\n",
    "        if (i < folds-1):\n",
    "            dataset_split.append(dataset_copy[i*fold_size:(i+1)*fold_size])\n",
    "        else:\n",
    "            dataset_split.append(dataset_copy[i*fold_size:len(dataset)])\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to perform training using  LearnLatentFactors Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldCV(data, factors, learnR, lamda, k, epochs, eps=0.001):\n",
    "    np.random.shuffle(data)\n",
    "    folds = cross_validation_split(data, k)\n",
    "    \n",
    "    listCVE = []\n",
    "    for i in range(len(folds)):\n",
    "        train = np.vstack([x for x in folds if x is not folds[i]])\n",
    "        valid = folds[i]\n",
    "\n",
    "        _, _, listTrainRMSE, listValidRMSE = trainMF(\\\n",
    "            data, valid, 943, 1682, learnR, lamda, factors, epochs, eps)\n",
    "            \n",
    "        listCVE.append(listValidRMSE[-1])\n",
    "    \n",
    "    return np.mean(listCVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieLdf = read_data() ### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Split the data into train and test set. The train set is further divided into train and validate set in kFoldCV function above \n",
    "\n",
    "trainData = movieLdf.values[0:int(0.9*100000)] \n",
    "testData = movieLdf.values[int(0.9*100000):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper paramters optimization to get best paramters that give use minimum rmse on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_Factors= 20  alpha= 0.005  lambda= 0.01\n",
      "RMSE on validation set =  1.0999056337461874\n",
      "n_Factors= 20  alpha= 0.005  lambda= 0.1\n",
      "RMSE on validation set =  1.069648250590203\n",
      "n_Factors= 20  alpha= 0.003  lambda= 0.01\n",
      "RMSE on validation set =  1.0661329946623537\n",
      "n_Factors= 20  alpha= 0.003  lambda= 0.1\n",
      "RMSE on validation set =  1.046282108508331\n",
      "n_Factors= 40  alpha= 0.005  lambda= 0.01\n",
      "RMSE on validation set =  1.10578560665887\n",
      "n_Factors= 40  alpha= 0.005  lambda= 0.1\n",
      "RMSE on validation set =  1.0865546917210298\n",
      "n_Factors= 40  alpha= 0.003  lambda= 0.01\n",
      "RMSE on validation set =  1.0721369953113398\n",
      "n_Factors= 40  alpha= 0.003  lambda= 0.1\n",
      "RMSE on validation set =  1.065423065430813\n"
     ]
    }
   ],
   "source": [
    "n_factors = [20, 40]\n",
    "listAlpha = [0.005, 0.003]\n",
    "listLamda = [0.01, 0.1]\n",
    "\n",
    "listRMSE = np.zeros((3, 3, 3))\n",
    "\n",
    "for i , factors in enumerate(n_factors):\n",
    "    for j, alpha in enumerate(listAlpha):\n",
    "        for k, lamda in enumerate(listLamda):\n",
    "            print(\"n_Factors=\", factors, \" alpha=\", alpha, \" lambda=\", lamda)\n",
    "            listRMSE[i, j, k] = kFoldCV(trainData, factors, alpha, lamda, 3, 10) #Using only train data which will be further divided into train and validate set inside the kFoldCV function\n",
    "            print(\"RMSE on validation set = \", listRMSE[i, j, k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above results shows that we got minimum RMSE on validation set with n_Factor=20, alpha= 0.003 and lambda= 0.1. So we will use these hyper paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p, q, listTrainRMSE, listTestRMSE = trainMF(trainData, testData, 943, 1682, 0.003, 0.1, 20, 50, 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2c916bc1788>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(listTrainRMSE, label=\"train RMSE\")\n",
    "plt.plot(listTestRMSE, label=\"test RMSE\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.937676496510638"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listTestRMSE[0] ###Rmse on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library 1 Surprise:\n",
    "\n",
    "Surprise is a Python scikit building and analyzing recommender systems.\n",
    "\n",
    " Users can use both built-in datasets (Movielens, Jester), and their own custom datasets.\n",
    "Provide various ready-to-use prediction algorithms such as baseline algorithms, neighborhood methods, matrix factorization-based ( SVD, PMF, SVD++, NMF), and many others. Also, various similarity measures (cosine, MSD, pearson…) are built-in.\n",
    "Provide tools to evaluate, analyse and compare the algorithms performance. Cross-validation procedures can be run very easily using powerful CV iterators (inspired by scikit-learn excellent tools), as well as exhaustive search over a set of parameters.\n",
    "The name SurPRISE (roughly :) ) stands for Simple Python RecommendatIon System Engine.\n",
    "\n",
    "We used SVD to solve the problem\n",
    "\n",
    "Singular value decomposition takes a rectangular matrix of gene expression data (defined as A, where A is a n x p matrix) in which the n rows represents the genes, and the p columns represents the experimental conditions. The SVD theorem states:\n",
    "\n",
    "A(nxp)= U(nxn) * S(nxp) * V.T(pxp)\n",
    "\n",
    "Where\n",
    "\n",
    "U.T*U = I(nxn)\n",
    "\n",
    "V.T*V = I(px)p  (i.e. U and V are orthogonal)\n",
    "\n",
    " \n",
    "\n",
    "Where the columns of U are the left singular vectors (gene coefficient vectors); S (the same dimensions as A) has singular values and is diagonal (mode amplitudes); and V.T has rows that are the right singular vectors (expression level vectors). The SVD represents an expansion of the original data in a coordinate system where the covariance matrix is diagonal.\n",
    "\n",
    " \n",
    "\n",
    "Calculating the SVD consists of finding the eigenvalues and eigenvectors of A*A.T and A.T*A. The eigenvectors of A.T*A make up the columns of V , the eigenvectors of A*A.T  make up the columns of U. Also, the singular values in S are square roots of eigenvalues from A*A.T or A.T*A.  The singular values are the diagonal entries of the S matrix and are arranged in descending order. The singular values are always real numbers. If the matrix A is a real matrix, then U and V are also real.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] y\n",
      "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to C:\\Users\\fahad/.surprise_data/ml-100k\n"
     ]
    }
   ],
   "source": [
    "# Use movielens-100K\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset, testset = train_test_split(data, test_size=.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9228534951706099\n",
      "{'n_factors': 120, 'n_epochs': 30, 'lr_all': 0.008, 'reg_all': 0.1}\n",
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.9209  0.9228  0.9278  0.9238  0.0029  \n",
      "Fit time          7.90    7.88    7.88    7.89    0.01    \n",
      "Test time         0.36    0.27    0.27    0.30    0.04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.92090295, 0.92281803, 0.92775973]),\n",
       " 'fit_time': (7.896497488021851, 7.8844685554504395, 7.881486654281616),\n",
       " 'test_time': (0.364790678024292, 0.27086424827575684, 0.2698338031768799)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- SVD ----- #\n",
    "\n",
    "param_grid = {'n_factors': [120, 140, 160], 'n_epochs': [30], 'lr_all': [0.003, 0.005, 0.008],\n",
    "              'reg_all': [0.08, 0.1, 0.15]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "gs.fit(data)\n",
    "algo = gs.best_estimator['rmse']\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])\n",
    "cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the optimal hyper paramters with SVD for matrix factorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD : Test Set\n",
      "RMSE: 0.9103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9102689311896246"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the new parameters with the train data and fit the model\n",
    "algo = SVD(n_factors=120, n_epochs=30, lr_all=0.008, reg_all=0.1)\n",
    "algo.fit(trainset)\n",
    "\n",
    "#Now do the prediction on test set\n",
    "test_pred = algo.test(testset)\n",
    "print(\"SVD : Test Set\")\n",
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library 2 Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Negative Matrix Factorization (NMF)\n",
    "\n",
    "Find two non-negative matrices (W, H) whose product approximates the non- negative matrix X. This factorization can be used for example for dimensionality reduction, source separation or topic extraction.\n",
    "\n",
    "The objective function is:\n",
    "\n",
    "0.5 * ||X - WH||_Fro^2\n",
    "+ alpha * l1_ratio * ||vec(W)||_1\n",
    "+ alpha * l1_ratio * ||vec(H)||_1\n",
    "+ 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
    "+ 0.5 * alpha * (1 - l1_ratio) * ||H||_Fro^2\n",
    "Where:\n",
    "\n",
    "||A||_Fro^2 = \\sum_{i,j} A_{ij}^2 (Frobenius norm)\n",
    "||vec(A)||_1 = \\sum_{i,j} abs(A_{ij}) (Elementwise L1 norm)\n",
    "For multiplicative-update (‘mu’) solver, the Frobenius norm (0.5 * ||X - WH||_Fro^2) can be changed into another beta-divergence loss, by changing the beta_loss parameter.\n",
    "\n",
    "The objective function is minimized with an alternating minimization of W and H.\n",
    "\n",
    "It uses Coordinate Descent (CD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset, folds=3):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = np.copy(dataset)\n",
    "    fold_size = math.ceil(len(dataset) / folds)\n",
    "    for i in range(folds):\n",
    "        if (i < folds-1):\n",
    "            dataset_split.append(dataset_copy[i*fold_size:(i+1)*fold_size])\n",
    "        else:\n",
    "            dataset_split.append(dataset_copy[i*fold_size:len(dataset)])\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldCV1(R, data, factors, lamda, k):\n",
    "    np.random.shuffle(data)\n",
    "    folds = cross_validation_split(data, k)\n",
    "    \n",
    "    listCVE = []\n",
    "    for i in range(len(folds)):\n",
    "        train = np.vstack([x for x in folds if x is not folds[i]])\n",
    "        valid = folds[i]\n",
    "        \n",
    "        RCopy = R.copy()\n",
    "        for x in valid:\n",
    "            RCopy[x[0]-1, x[1]-1] = 0\n",
    "\n",
    "        model = NMF(n_components=factors, init='random', alpha=lamda)\n",
    "        W = model.fit_transform(RCopy)\n",
    "        H = model.components_\n",
    "        \n",
    "        R_pred = np.dot(W, H)\n",
    "        \n",
    "        rmse = 0\n",
    "        for x in valid:\n",
    "            rmse += (x[2] - R_pred[x[0]-1, x[1]-1])**2\n",
    "        rmse /= valid.shape[0]\n",
    "        rmse = np.sqrt(rmse)\n",
    "            \n",
    "        listCVE.append(rmse)\n",
    "    \n",
    "    return np.mean(listCVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieLdf = pd.read_csv(\"u.data\", delimiter=\"\\t\", header=None)\n",
    "movieLdf = movieLdf.drop(movieLdf.columns[3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = movieLdf.pivot(index = 0, columns = 1, values = 2).fillna(0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the data into train and test set. The train set is further divided into train and validate set in kFoldCV1 function above \n",
    "\n",
    "trn , tst = train_test_split(movieLdf, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tst.values:\n",
    "    new_df[x[0]-1, x[1]-1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper paramter optimization with  3-folds cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validataion RMSE is \n",
      "\n",
      "\n",
      "n_Factors= 2  lambda= 0.001\n",
      "RMSE= 3.168940044834376\n",
      "n_Factors= 2  lambda= 0.1\n",
      "RMSE= 3.170897553576435\n",
      "n_Factors= 4  lambda= 0.001\n",
      "RMSE= 3.1051451443952733\n",
      "n_Factors= 4  lambda= 0.1\n",
      "RMSE= 3.1054734527947514\n",
      "n_Factors= 5  lambda= 0.001\n",
      "RMSE= 3.090639067795783\n",
      "n_Factors= 5  lambda= 0.1\n",
      "RMSE= 3.0933526522721304\n",
      "n_Factors= 7  lambda= 0.001\n",
      "RMSE= 3.0706652153821588\n",
      "n_Factors= 7  lambda= 0.1\n",
      "RMSE= 3.075249407530737\n",
      "n_Factors= 9  lambda= 0.001\n",
      "RMSE= 3.070228741203023\n",
      "n_Factors= 9  lambda= 0.1\n",
      "RMSE= 3.0747962556417403\n",
      "n_Factors= 11  lambda= 0.001\n",
      "RMSE= 3.07129432249428\n",
      "n_Factors= 11  lambda= 0.1\n",
      "RMSE= 3.077932790032984\n",
      "n_Factors= 15  lambda= 0.001\n",
      "RMSE= 3.085845518297336\n",
      "n_Factors= 15  lambda= 0.1\n",
      "RMSE= 3.08697013427585\n",
      "n_Factors= 20  lambda= 0.001\n",
      "RMSE= 3.10654914748768\n",
      "n_Factors= 20  lambda= 0.1\n",
      "RMSE= 3.109057918116239\n",
      "n_Factors= 80  lambda= 0.001\n",
      "RMSE= 3.27823543830746\n",
      "n_Factors= 80  lambda= 0.1\n",
      "RMSE= 3.27645402958872\n",
      "n_Factors= 160  lambda= 0.001\n",
      "RMSE= 3.4124761577735527\n",
      "n_Factors= 160  lambda= 0.1\n",
      "RMSE= 3.410512619115572\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_factors = [2, 4, 5, 7, 9 , 11, 15, 20, 80, 160]\n",
    "listLamda = [0.001, 0.1]\n",
    "\n",
    "listRMSE = np.zeros((10, 2))\n",
    "\n",
    "print(\"Validataion RMSE is \\n\\n\")\n",
    "for i , factors in enumerate(n_factors):\n",
    "        for j, lamda in enumerate(listLamda):\n",
    "            print(\"n_Factors=\", factors, \" lambda=\", lamda)\n",
    "            listRMSE[i, j] = kFoldCV1(new_df, trn.values, factors, lamda, 3)\n",
    "            print(\"RMSE=\", listRMSE[i, j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Above results shows that we got minimum RMSE on validation set with n_Factor=9, alpha= 0.001. So we will use these hyper paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=9, init='random', alpha=0.001)\n",
    "W = model.fit_transform(new_df)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.763689353496737"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.dot(W,H)\n",
    "print(\"RMSE on test set is\")\n",
    "np.sqrt(np.mean(np.square(tst.values[:,2] -\\\n",
    "                [r[x[0]-1, x[1]-1] for x in tst.values])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My naive implementation of matrix factorization give 2.9 Rmse on test set, build in library sci-learn matrix factorization which gives 2.7 Rmse on test set  as compared to sci-learn surprise library which give 0.9 Rmse on test set. This shows that Surprise's SVD is performing best with with RMSE of 0.9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
